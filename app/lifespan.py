# app/lifespan.py
from typing import TypedDict
from collections.abc import AsyncIterator
from contextlib import asynccontextmanager

from fastapi import FastAPI
from loguru import logger
from langchain_ollama import ChatOllama
from langchain_core.runnables import Runnable

from app.core.config import get_settings
from app.core.llm_loader import get_llm
from app.agents.basic_agent import assemble_langgraph_agent


class AppState(TypedDict):
    """
    å®šä¹‰åº”ç”¨ç”Ÿå‘½å‘¨æœŸä¸­å…±äº«çŠ¶æ€çš„ç»“æ„ã€‚
    """

    llm: ChatOllama
    agent: Runnable


@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncIterator[AppState]:
    # -------- å¯åŠ¨ --------
    get_settings()

    logger.info("ğŸš€ åº”ç”¨å¯åŠ¨,é…ç½®å·²å°±ç»ªã€‚")
    # åŠ è½½ LLM
    llm = get_llm()

    # LLMå¥åº·æ£€æŸ¥
    try:
        test_response = await llm.ainvoke("Hello")
        logger.success(f"âœ… LLM å¥åº·æ£€æŸ¥é€šè¿‡: {test_response.content[:50]}...")
    except Exception as e:
        logger.error(f"âŒ LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        raise RuntimeError("LLM åˆå§‹åŒ–å¤±è´¥ï¼Œåº”ç”¨å¯åŠ¨ä¸­æ­¢")

    # ç»„è£… LangGraph Agent
    agent = await assemble_langgraph_agent(llm)

    # æ›´åŠ ç±»å‹å®‰å…¨çš„å†™æ³•
    yield AppState(llm=llm, agent=agent)

    # -------- å…³é—­ --------

    logger.info("åº”ç”¨å…³é—­ï¼Œèµ„æºå·²é‡Šæ”¾ã€‚")
